{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO3JHLZoLb9qFa6YJOLr0xT"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "7f7c57be"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sn\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "import keras\n",
        "import tensorflow as tf\n",
        "from sklearn.metrics import confusion_matrix,ConfusionMatrixDisplay\n",
        "from sklearn.metrics import accuracy_score, f1_score\n",
        "from sklearn import metrics\n",
        "import os\n",
        "from datetime import datetime"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class BuildingModel: # Class BuildingModel is for quick auto-train neural network with mine architecture \n",
        "    def __init__(self, data, threshold, test_size, train_test_rand_seed, f1_lim,columns_to_drop,target_name,what_to_detect): # defining variables\n",
        "        self.data = data\n",
        "        self.threshold = threshold\n",
        "        self.test_size = test_size\n",
        "        self.train_test_rand_seed = train_test_rand_seed\n",
        "        self.f1_lim = f1_lim\n",
        "        self.columns_to_drop = columns_to_drop\n",
        "        self.target_name = target_name\n",
        "        self.what_to_detect = what_to_detect\n",
        "\n",
        "    def preprocess_data(self): # data preprocessing, opening .csv, dropping specific columns, finding the most corelatted columns, splitting for test and train set\n",
        "        df = pd.read_csv(self.data) \n",
        "        df = df.drop(self.columns_to_drop, axis=1)\n",
        "        corr_matrix = df.corr()\n",
        "        ttl = df[self.target_name]\n",
        "        corr_type = corr_matrix[self.target_name]\n",
        "        corr_type.sort_values(ascending=False)\n",
        "        pos = corr_type.sort_values(ascending=False)\n",
        "        columns = []\n",
        "        for i in range(0, len(pos)):\n",
        "            if abs(pos[i]) > self.threshold and abs(pos[i]) < 0.99:\n",
        "                columns.append(pos.index[i])\n",
        "        result_s = df.loc[:, df.columns.intersection(columns)]\n",
        "        X_train, X_test, y_train, y_test = train_test_split(result_s, ttl, test_size=self.test_size, stratify=ttl,\n",
        "                                                            random_state=self.train_test_rand_seed)\n",
        "        return X_train, X_test, y_train, y_test\n",
        "    \n",
        "    def get_current_time(self): # taking a current time to use it in folder name \n",
        "        now = datetime.now()\n",
        "        current_time = now.strftime(\"%H-%M-%S\")\n",
        "        return current_time\n",
        "\n",
        "\n",
        "    def train_and_save_models(self, X_train, X_test, y_train, y_test): # training model and saving it in a folder with ROC Curve and Confusion matrix and train and test set\n",
        "        for j in range(2, 5):\n",
        "            for i in range(1, 40):\n",
        "                model_nn = Sequential()\n",
        "                model_nn.add(Dense(300, activation='relu', input_dim=X_train.shape[1]))\n",
        "                model_nn.add(Dense(250, activation='relu'))\n",
        "                model_nn.add(Dense(100, activation='relu'))\n",
        "                model_nn.add(Dense(50, activation='relu'))\n",
        "                model_nn.add(Dense(125, activation='relu'))\n",
        "                model_nn.add(Dense(375, activation='relu'))\n",
        "                model_nn.add(Dense(400, activation='relu'))\n",
        "                model_nn.add(Dense(500, activation='relu'))\n",
        "                model_nn.add(Dense(1, activation='sigmoid'))\n",
        "                model_nn.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "                model_nn.fit(X_train, y_train, epochs=i * 20, batch_size=2 ** j)\n",
        "                predictions = model_nn.predict(X_test)\n",
        "                predicted = []\n",
        "                for p in range(0, len(predictions)): # sigmoid threshold setting as 0.5\n",
        "                    if predictions[p][0] > 0.5:\n",
        "                        predicted.append(1)\n",
        "                    else:\n",
        "                        predicted.append(0)\n",
        "                real_pred = pd.DataFrame({'test_data': y_test, 'predicted_data': predicted})\n",
        "                test_values = real_pred['test_data'].tolist()\n",
        "                prediction_values = real_pred['predicted_data'].tolist()\n",
        "                f1 = f1_score(test_values, prediction_values)\n",
        "                if f1 > self.f1_lim:\n",
        "                    current_time = self.get_current_time()\n",
        "                    folder_name = f'model_time_{current_time}__f1_{f1}'\n",
        "\n",
        "                    os.makedirs(folder_name)\n",
        "                    folder_path = os.path.join(os.getcwd(), folder_name)\n",
        "                    model_nn.save(os.path.join(folder_path,\n",
        "                                               f'model_ep_{i * 20}_bt_{2 ** j}_f1_{f1}_threshold_{self.threshold}_'\n",
        "                                               f'columns_{X_train.shape[1]}_random_state_{self.train_test_rand_seed}.h5'))\n",
        "                    print(\"model saved\")\n",
        "                    X_train.to_csv(os.path.join(folder_path, 'X_train.csv'))\n",
        "                    X_test.to_csv(os.path.join(folder_path, 'X_test.csv'))\n",
        "                    y_train.to_csv(os.path.join(folder_path, 'y_train.csv'))\n",
        "                    y_test.to_csv(os.path.join(folder_path, 'y_test.csv'))\n",
        "                    fpr, tpr, thresholds = metrics.roc_curve(y_test, predicted)\n",
        "                    auc = metrics.auc(fpr, tpr)\n",
        "                    plt.figure()\n",
        "                    plt.plot(fpr, tpr, label='ROC curve (AUC = %0.2f)' % auc)\n",
        "                    plt.plot([0, 1], [0, 1], 'k--')\n",
        "                    plt.xlim([0.0, 1.0])\n",
        "                    plt.ylim([0.0, 1.05])\n",
        "                    plt.xlabel('True positive rate')\n",
        "                    plt.ylabel('Fasle positive rate')\n",
        "                    plt.title('ROC curve')\n",
        "                    plt.legend(loc=\"lower right\")\n",
        "                    plt.savefig(os.path.join(folder_path, 'ROC_Curve.png'))\n",
        "                    conf_matrix = confusion_matrix(y_test, predicted)\n",
        "                    display = ConfusionMatrixDisplay(conf_matrix, display_labels=[f'NON-{self.what_to_detect}', f'{self.what_to_detect}'])\n",
        "                    display.plot(cmap='viridis')\n",
        "                    ax = plt.gca()\n",
        "                    ax.set(title=f'Confusion Matrix for the {self.what_to_detect} Detection Model')\n",
        "                    for text in ax.texts:\n",
        "                        text.set_fontsize(30)\n",
        "                    plt.savefig(os.path.join(folder_path, 'Confusion_Matrix.png'))\n",
        "                else:\n",
        "                    continue\n",
        "\n",
        "model = BuildingModel(data=\"dataframe.csv\",threshold= 0.3,test_size=0.3,train_test_rand_seed=2,f1_lim=0.01,columns_to_drop=['Column0','Column1'],target_name='Target',what_to_detect='Target')\n",
        "X_train, X_test, y_train, y_test = model.preprocess_data() \n",
        "model.train_and_save_models(X_train, X_test, y_train, y_test)"
      ],
      "metadata": {
        "id": "nyjrii3i83Bt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "#setting column names\n",
        "column_names = [f'Column{i}' for i in range(3495)] \n",
        "# generating target values\n",
        "target = np.random.randint(0, 2, size=(1000, 1))\n",
        "# generating data\n",
        "data = np.random.randint(0, 100, size=(1000, 3495))\n",
        "data = data/1000\n",
        "# setting datafram\n",
        "df = pd.DataFrame(data, columns=column_names)\n",
        "df['Target'] = target\n",
        "# saving in .csv formatdf.to_csv('dataframe.csv')"
      ],
      "metadata": {
        "id": "rW6iJYBf9I_8"
      },
      "execution_count": 9,
      "outputs": []
    }
  ]
}
